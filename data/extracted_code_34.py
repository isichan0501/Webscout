from __future__ import annotations
from typing import List, Optional
from webscout.LLM import LLM
from webscout import DeepWEBS
import warnings

system_message: str = (
    "As an AI assistant, I have been designed with advanced capabilities, including real-time access to online resources. This enables me to enrich our conversations and provide you with informed and accurate responses, drawing from a vast array of information. With each interaction, my goal is to create a seamless and meaningful connection, offering insights and sharing relevant content."
    "My directives emphasize the importance of respect, impartiality, and intellectual integrity. I am here to provide unbiased responses, ensuring an ethical and respectful exchange. I will respect your privacy and refrain from sharing any personal information that may be obtained during our conversations or through web searches, only utilizing web search functionality when necessary to provide the most accurate and up-to-date information."
    "Together, let's explore a diverse range of topics, creating an enjoyable and informative experience, all while maintaining the highest standards of privacy and respect"
)

# Ignore the specific UserWarning
warnings.filterwarnings("ignore", category=UserWarning, module="curl_cffio", lineno=205)

LLM = LLM(model="mistralai/Mixtral-8x22B-Instruct-v0.1", system_message=system_message)

def perform_web_search(query):
    # Initialize the DeepWEBS class
    D = DeepWEBS()

    # Set up the search parameters
    search_params = D.DeepSearch(
        queries=[query],  # Query to search
        result_num=10,  # Number of search results
        safe=True,  # Enable SafeSearch
        types=["web"],  # Search type: web
        extract_webpage=True,  # True for extracting webpages
        overwrite_query_html=True,
        overwrite_webpage_html=True,
    )

    # Execute the search and retrieve results
    results = D.queries_to_search_results(search_params)
    return results

def chat(user_input: str, result_num: int = 10) -> Optional[str]:
    """
    Chat function to perform a web search based on the user input and generate a response using the LLM model.

    Parameters
    ----------
    user_input : str
        The user input to be used for the web search
    max_results : int, optional
        The maximum number of search results to include in the response, by default 10

    Returns
    -------
    Optional[str]
        The response generated by the LLM model, or None if there is no response
    """
    # Perform a web search based on the user input
    search_results = perform_web_search(user_input)

    # Extract URLs from search results
    url_results = []
    for result in search_results[0]['query_results']:
        url_results.append(f"{result['title']} ({result['site']}): {result['url']}")

    # Format search results
    formatted_results = "\n".join(url_results)

    # Define the messages to be sent, including the user input, search results, and system message
    messages = [
        {"role": "user", "content": f"User question is:\n{user_input}\nwebsearch results are:\n{formatted_results}"},
    ]

    # Use the chat method to get the response
    response = LLM.chat(messages)
    return response

if __name__ == "__main__":
    while True:
        # Get the user input
        user_input = input("User: ")

        # Perform a web search based on the user input
        response = chat(user_input)

        # Print the response
        if response:
            print("AI:", response)
        else:
            print("No response")

